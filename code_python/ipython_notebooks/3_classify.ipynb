{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphlab as gl\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Files folder\n",
    "dataFolder = '../data/'\n",
    "featuresFolder = '../output/features/' \n",
    "predictionsFolder = '../output/predictions/'\n",
    "if not os.path.exists(predictionsFolder):\n",
    "    os.makedirs(predictionsFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usersData_sf = gl.SFrame.read_csv(dataFolder+'usersdata.csv', header=False, delimiter='\\t')\n",
    "usersData_sf.rename({'X1':'userId','X2':'sex','X3':'timePassedValidation','X4':'ageGroup','X5':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading the features\n",
    "graphFeatures_sf = gl.SFrame.read_csv(featuresFolder+'graph_features.csv', header=True)\n",
    "sequenceFeatures_sf = gl.SFrame.read_csv(featuresFolder+'sequence_bigram_features.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Selecting the users who have made at least one action\n",
    "usersData_sf = sequenceFeatures_sf[['userId']].join(usersData_sf, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_sf = usersData_sf.filter_by([1], \"label\")\n",
    "negative_sf = usersData_sf.filter_by([0], \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numOfFolds = 10\n",
    "np.random.seed(2015)\n",
    "\n",
    "positive_sf['fold']=np.random.random_sample(positive_sf.num_rows())\n",
    "positive_sf['fold']=positive_sf.apply(lambda x: int(x['fold']*numOfFolds)+1)\n",
    "positive_sf['shuffle'] = np.random.random_sample(positive_sf.num_rows())\n",
    "positive_sf = positive_sf.sort('shuffle')\n",
    "positive_sf.remove_column('shuffle')\n",
    "\n",
    "negative_sf['fold']=np.random.random_sample(negative_sf.num_rows())\n",
    "negative_sf['fold']=negative_sf.apply(lambda x: int(x['fold']*numOfFolds)+1)\n",
    "negative_sf['shuffle'] = np.random.random_sample(negative_sf.num_rows())\n",
    "negative_sf = negative_sf.sort('shuffle')\n",
    "negative_sf.remove_column('shuffle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To save the prediction\n",
    "def saveDict(fn,dict_rap):\n",
    "    f=open(fn, \"w\")\n",
    "    w = csv.writer(f)\n",
    "    for key, val in dict_rap.items():\n",
    "        w.writerow([key, val])\n",
    "    f.close()\n",
    "     \n",
    "def readDict(fn):\n",
    "    f=open(fn,'r')\n",
    "    dict_rap={}\n",
    "     \n",
    "    for key, val in csv.reader(f):\n",
    "        dict_rap[key]=eval(val)\n",
    "    f.close()\n",
    "    return(dict_rap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the fullDataset\n",
    "\n",
    "# puttin the negative and positive together\n",
    "fullDataset_sf = positive_sf\n",
    "fullDataset_sf = fullDataset_sf.append(negative_sf)\n",
    "\n",
    "# Adding features:\n",
    "fullDataset_sf = fullDataset_sf.join(graphFeatures_sf, on='userId', how='left')\n",
    "fullDataset_sf = fullDataset_sf.join(sequenceFeatures_sf, on='userId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(fullDataset_sf, featureList, featureListName, numOfFolds):\n",
    "    \n",
    "    accuracy = {}\n",
    "    predictions_sf = gl.SFrame()\n",
    "\n",
    "    for currentFold in range(1,numOfFolds+1):\n",
    "        \n",
    "        startTime = time.time()\n",
    "        \n",
    "        print str(round(time.time() - startTime,2)) + \": Creating train and test sets - Fold: \" + str(currentFold)\n",
    "\n",
    "        train_sf = fullDataset_sf.filter_by([currentFold],'fold', exclude=True)\n",
    "        test_sf = fullDataset_sf.filter_by([currentFold],'fold')\n",
    "\n",
    "        predictionsFold_sf = test_sf[['userId', 'label', 'fold']]\n",
    "\n",
    "        print str(round(time.time() - startTime,2)) + \": Training the model - Fold: \" + str(currentFold)\n",
    "\n",
    "        model = gl.boosted_trees_classifier.create(train_sf, \n",
    "                                            target='label', \n",
    "                                            verbose=False,\n",
    "                                            max_iterations = 3,\n",
    "                                            class_weights = 'auto',\n",
    "                                            features = featureList                                        \n",
    "                                            )\n",
    "\n",
    "        accuracy[currentFold] = model.evaluate(test_sf)\n",
    "\n",
    "        print str(round(time.time() - startTime,2))+\": Saving the predictions - Fold: \" + str(currentFold)\n",
    "        print \"Accuracy: \" + str(accuracy[currentFold]['accuracy'])\n",
    "\n",
    "        predictionsFold_sf['probability'] = model.predict(test_sf, output_type='probability')\n",
    "        predictionsFold_sf['margin'] = model.predict(test_sf, output_type='margin')\n",
    "        predictions_sf = predictions_sf.append(predictionsFold_sf)\n",
    "\n",
    "    print \"\\n*** Done! Saving all predictions ...\"    \n",
    "\n",
    "    predictions_sf.save(predictionsFolder+'predictions_'+featureListName+'_'+str(numOfFolds)+'_folds.csv', format='csv')    \n",
    "    saveDict(predictionsFolder+'accuracy_'+featureListName+'_'+str(numOfFolds)+'_folds.txt',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculating the AUPR and AUC based on the predictions\n",
    "\n",
    "def evaluate(featureListName, numOfFolds):\n",
    "    predictions_sf = gl.SFrame.read_csv(predictionsFolder+'predictions_'+featureListName+'_'+str(numOfFolds)+'_folds.csv', verbose=False)\n",
    "    \n",
    "    totalAUPR = []\n",
    "    totalAUROC = []\n",
    "\n",
    "    for i in range(1,numOfFolds):\n",
    "        predictionsFold_sf = predictions_sf.filter_by(i,'fold')\n",
    "        predictionsFold_sf = predictionsFold_sf.sort([('probability', False), ('margin', False)])\n",
    "\n",
    "        precision, recall, thresholds = precision_recall_curve(y_true=predictionsFold_sf['label'], probas_pred=predictionsFold_sf['probability'], pos_label=1)\n",
    "        totalAUPR.append(auc(recall, precision))\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(predictionsFold_sf['label'], predictionsFold_sf['probability'])\n",
    "        totalAUROC.append(auc(fpr, tpr))\n",
    "\n",
    "    print featureListName\n",
    "    \n",
    "    print 'AUPR:'\n",
    "    print '%0.3f +/- ' %np.mean(totalAUPR) + '%0.3f' %np.std(totalAUPR)\n",
    "\n",
    "    print 'AUROC:'\n",
    "    print '%0.3f +/-' %np.mean(totalAUROC) + '%0.3f' %np.std(totalAUROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Running the experiments\n",
    "\n",
    "# graph features\n",
    "featureList = graphFeatures_sf.column_names()\n",
    "featureList.remove('userId')\n",
    "classify(fullDataset_sf, featureList, 'graph_features', numOfFolds)\n",
    "\n",
    "# sequence features\n",
    "featureList = sequenceFeatures_sf.column_names()\n",
    "featureList.remove('userId')\n",
    "classify(fullDataset_sf, featureList, 'bigram_features', numOfFolds)\n",
    "\n",
    "# both graph and sequence features\n",
    "featureList = graphFeatures_sf.column_names()\n",
    "featureList.remove('userId')\n",
    "featureList += sequenceFeatures_sf.column_names()\n",
    "featureList.remove('userId')\n",
    "classify(fullDataset_sf, featureList, 'graph_and_bigram_features', numOfFolds)\n",
    "\n",
    "# both graph and sequence and demographics features\n",
    "featureList = fullDataset_sf.column_names()\n",
    "featureList.remove('userId')\n",
    "featureList.remove('fold')\n",
    "featureList.remove('label')\n",
    "classify(fullDataset_sf, featureList, 'all_features', numOfFolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Computing the results\n",
    "\n",
    "evaluate('graph_features', numOfFolds)\n",
    "evaluate('bigram_features', numOfFolds)\n",
    "evaluate('graph_and_bigram_features', numOfFolds)\n",
    "evaluate('all_features', numOfFolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
